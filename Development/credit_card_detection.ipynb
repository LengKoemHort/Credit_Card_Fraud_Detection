{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use options to see all column\n",
    "pd.options.display.max_columns = None\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .tail used to get the last five column\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check row and column\n",
    "print(\"Number of columns: {}\".format(data.shape[1]))\n",
    "print(\"Number of rows: {}\".format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check mission value by using data.info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null value\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is already defined and contains your dataset\n",
    "print(data['Class'].value_counts())\n",
    "\n",
    "# Separate the dataset into fraud and normal transactions\n",
    "Fraud = data[data['Class'] == 1]\n",
    "Normal = data[data['Class'] == 0]\n",
    "\n",
    "# Count classes\n",
    "count_classes = pd.Series(data['Class']).value_counts(sort=True)\n",
    "\n",
    "# Plotting\n",
    "colors = ['blue', 'red']  # Customize colors for Normal and Fraud\n",
    "count_classes.plot(kind=\"bar\", color=colors)\n",
    "\n",
    "LABELS = [\"Normal\", \"Fraud\"]\n",
    "plt.xticks(range(2), LABELS)\n",
    "\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Transaction Class Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then we check the normal and fraud dataset\n",
    "Fraud = data[data['Class'] == 1]\n",
    "Normal = data[data['Class'] == 0]\n",
    "\n",
    "print(Fraud.shape, Normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the column time\n",
    "data = data.drop(['Time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check duplicated values\n",
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we drop duplicated values\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to drop duplicated values\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After we drop duplicated values\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class labels\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use standarscaler for reduces bias improves the learning process.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "data['Amount'] = sc.fit_transform(pd.DataFrame(data['Amount']))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis = 1)\n",
    "y=data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"KNeighbors\": KNeighborsClassifier(),\n",
    "    \"Xgboost\": XGBClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n=========={name}===========\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Accuaracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Recall: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n F1 Score: {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prediction = XGBClassifier()\n",
    "data_prediction.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(data_prediction, 'XGboot_Model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into fraud and normal transactions\n",
    "data_fraud = data[data['Class'] == 1]\n",
    "data_normal = data[data['Class'] == 0]\n",
    "\n",
    "# Function to print rows with commas\n",
    "def print_rows_with_commas(df, n=4):\n",
    "    for index, row in df.head(n).iterrows():\n",
    "        print(', '.join(map(str, row.values)))\n",
    "\n",
    "# Print the first 2 rows of fraud data  \n",
    "print(\"Fraud Data:\")\n",
    "print_rows_with_commas(data_fraud)\n",
    "\n",
    "# Print the first 2 rows of normal data\n",
    "print(\"\\nNormal Data:\")\n",
    "print_rows_with_commas(data_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model = joblib.load(\"XGboot_Model.pkl\")\n",
    "# Make the prediction\n",
    "pred = pred_model.predict([\n",
    "    [-2.3122265423263, 1.95199201064158, -1.60985073229769, 3.9979055875468, -0.522187864667764, -1.42654531920595, -2.53738730624579, 1.39165724829804, -2.77008927719433, -2.77227214465915, 3.20203320709635, -2.89990738849473, -0.595221881324605, -4.28925378244217, 0.389724120274487, -1.14074717980657, -2.83005567450437, -0.0168224681808257, 0.416955705037907, 0.126910559061474, 0.517232370861764, -0.0350493686052974, -0.465211076182388, 0.320198198514526, 0.0445191674731724, 0.177839798284401, 0.261145002567677, -0.143275874698919, -0.4175162445753002]\n",
    "])\n",
    "\n",
    "# Check the prediction and print the corresponding class\n",
    "if pred[0] == 0:\n",
    "    print(\"The transaction is Normal.\")\n",
    "elif pred[0] == 1:\n",
    "    print(\"The transaction is Fraud.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model = joblib.load(\"XGboot_Model.pkl\")\n",
    "# Make the prediction\n",
    "pred = pred_model.predict([\n",
    "    [1.99580500482354, -0.185640469490288, -1.63055972869549, -0.123601632903268, 0.253957698895392, -0.912552023158912, 0.320712899205896, -0.243601532270024, 0.301719410344464, 0.106709606516659, 0.776338360874582, 0.751848210917616, -0.377450224359188, 0.860129915507045, 0.100224221845141, 0.0501332969452917, -0.722079290418566, -0.0250280347528174, 0.476523948758478, -0.163539137109292, -0.100148633773135, -0.331418973307353, 0.158847276366556, -0.481294479785805, -0.0938169937195864, -0.148649095179115, -0.0652773488212963, -0.0691752385113206, -0.2685631132328121]\n",
    "])\n",
    "\n",
    "# Check the prediction and print the corresponding class\n",
    "if pred[0] == 0:\n",
    "    print(\"The transaction is Normal.\")\n",
    "elif pred[0] == 1:\n",
    "    print(\"The transaction is Fraud.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
